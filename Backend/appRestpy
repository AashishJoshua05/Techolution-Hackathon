from flask import Flask, request
import librosa
import numpy as np
from keras.models import load_model
from flask_cors import CORS



app = Flask(__name__)
CORS(app)
TARGET_SHAPE = (13, 51)
model = load_model('LSTM_trial_model.h5')

# Function to extract MFCC features
def extract_mfcc_features(audio, sr, num_cepstral=13, frame_length=0.02, frame_stride=0.02,
                          num_filters=32, fft_length=320, preemphasis_coeff=0.98):
    # Apply pre-emphasis
    audio = np.append(audio[0], audio[1:] - preemphasis_coeff * audio[:-1])

    # Compute the mel spectrogram
    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=num_filters, n_fft=fft_length,
                                                     hop_length=int(frame_stride * sr), window="hann")

    # Logarithm of the mel spectrogram
    log_mel_energy = np.log(mel_spectrogram + 1e-9)

    # Extract MFCC features using DCT
    mfcc_features = librosa.feature.mfcc(S=log_mel_energy, n_mfcc=num_cepstral)

    # Adjust shape to target shape
    mfcc_features = mfcc_features[:, :TARGET_SHAPE[1]] if mfcc_features.shape[1] > TARGET_SHAPE[1] \
        else np.pad(mfcc_features, pad_width=((0, 0), (0, TARGET_SHAPE[1] - mfcc_features.shape[1])),
                   mode='symmetric')
    mfcc_features = mfcc_features[:TARGET_SHAPE[0], :] if mfcc_features.shape[0] > TARGET_SHAPE[0] \
        else np.pad(mfcc_features, pad_width=((0, TARGET_SHAPE[0] - mfcc_features.shape[0]), (0, 0)),
                   mode='symmetric')

    return np.array([mfcc_features])



@app.route('/api/createAudio', methods=['POST'])
def create_audio():
    if request.method == 'POST':
        if 'audio' not in request.files:
            return 'No audio part'
        
        file = request.files['audio']

        # Change the path where you want to store the audio file
        file.save('doorStatus.wav')  # Modify this path as needed
        
        audio, sr = librosa.load('C:\\Users\\91900\\Desktop\\Coding\\Techolution\\Backend\\doorStatus.wav', sr=None)
        mfcc_features = extract_mfcc_features(audio, sr)
        prediction = model.predict(mfcc_features)
        return str(np.argmax(prediction))

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=3233)